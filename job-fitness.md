# About this document

# Mission alignment

I can care ML interpretability and building responsible and safe AI systems. Related experience:

- Postdoc research experience on interpretable ML algoirthms, with 2 publications
- Industrial experience dedicated to create interpretable ML systems, spanning my recent 3 jobs
  - (perhaps give some examples)

Below are my answers to multiple aspects of job requirements.

# "You may be a good fit if you"

## Have 5-10+ years of experience building software and are highly proficient in at least one programming language (e.g., Python, Rust, Go, Java) and productive with python

- Have been coding in Python 15+ years, with certain exposure to programming languages such as TypeScript, C++, and Java,
- 10+ years of experience in writing software, spanning from hobby projects, to implementing research tools and developing corporate systems. 
- 4 years of professional software engineering experience (mostly ML system, and certain exposure to Fullstack roles)

## Have some experience contributing to empirical AI research projects

- I have ~3 years of empirical AI research projects, such as:
  - developing practically useful and interpretable ML algorithms for market research (currently at Cambri) and environmental impact quantification (at Upright). 
  - at Unity, developing privacy-constrained conversion prediction algorithms (a research pilot project) and CHAP-based explainability tools for deep learning models.
- In addition, I have 6+ years of research experience in the academia, focusing on designing data mining algorithms with theoretical guarantee and practical usefulness.

The above experience equips me with the necessary knowledge and skills to conduct research engineering tasks efficiently and communicate with researchers effectively


## Have a strong ability to prioritize and direct effort toward the most impactful work and are comfortable operating with ambiguity and questioning assumptions.

- made big contribution to the ML model development at Cambri, 
  - questioning existing model assumptions and adjust modeling choices, leading to substantial model performance improvement (model accuracy improved ~70% to 80+% across multiple model variants)
  - develop data snapshoting component to enhancing performance reproducibility, which is crucial to win customer trust
  - improve experimentation efficiency via choosing the proper evaluation setup and implementing hierarchical configuration system
  - fix model compatibility issues caused by code changes, leading to more robust inference functionality
- data pipeline optimization: 
  - designed part of data pipeline codebase to promoting better modularity and extensibility
  - outcome: enabling much faster feature engineering iteration with 50x less code and 25% faster data processing speed

## Prefer fast-moving collaborative projects to extensive solo efforts

- I enjoy working in a fast moving environment, as demonstrated by my recent work experience in startups
- I also enjoy collaborating with others. I believe collaboration is a great opportunity to learn from others and improve.
- Two evidence for my team spirit:
  - the recent Cambri Cultural Hero award to me, stating "(he) says an opinion, asks for opinions, listens to others, ackowledge the others' achievement")
  - data pipeline refactoring project at Unity: the project is not just about refactoring, but also includes working closely a senior ALE and asks for his opinion on key design choices,
    - and coordinating with external teams so that the final migration ran smoothly without affecting production system

## Want to learn more about machine learning research and its applications and collaborate closely with researchers

My passion for machine learning research is consistent, demonstrated by my previous contribution to the research community and recent experience in the industrial setting. 

I was a ML researcher and I have positioned me as ML research engineer, always willing to work closely with researcher and learn from them.

## Care about the societal impacts and ethics of your work

I aspire to make positive impacts via technical innovation. Such aspiration is demonstrated by:

- my doctoral thesis titled "data science for social good", in which I invented algorithms to help address society issues (polarization, misinformation, and fairness) in the online sphere
- my current role at Cambri helps companies to innovate products more effectively, with the potential of reducing resource waste
- my previous role at Upright focuses on measuring companies' environmental impact, which has the potential to drive sustainable business operation

# "Strong candidates may also have experience with:"

## Designing a code base so that anyone can quickly code experiments, launch them, and analyze their results without hitting bugs

I have created a few open-source repos, in which code quality and usability is put into first place:

- stgym: a ML system experiment with different GNN models for spatial transcriptomics analysis
- ers: a suite of efficient sampling and counting algorithms for rule-set models
- corset: interpretable multi-label rule set learning algorithms

- To ensure code quality, I applied test drive development and standard software QA practices (linting, type-checking, etc)
- Usability is also a big part of my effort, since I am the first user of the software that I write. Making the software easy-to-use equals making my life easier

## Optimizing the performance of large-scale distributed systems

- Refer to the data pipeline refactoring project (you need to expand this)
- Currently, I'm gaining more hands-on experience through the spatial transcriptomics research project, in which I need to launch a large number of model training experiments in a multi-GPU setting

## Collaborating closely with researchers

I myself was a researcher working in the academia and have rich experience working in different research settings. 

(If this doesn't qualify, let me know)

## Language modeling with transformers

(This is my main weakness)

This is something I am actively learning right now. I have been very excited about the interpretability research at Anthropic.

## GPUs or Pytorch

My experience with GPU and Pytorch includes:

- in stgym project, implementing distributed training pipeline for GNN models, optimizing CUDA memory usage and speed (in Pytorch)
- Large scale multi-GPU training of deep learning models (using Tensorflow at Unity)
- CUDA programming: implemented GPU-based sorting algorithm, image segmentation algorithm, correlation coefficient calculation algorithm
