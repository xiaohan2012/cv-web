# Cover Letter

Dear Goodfire Team,

I am writing to express my strong interest in the Research Engineer position at Goodfire. Your mission to advance AI interpretability and build safe, trustworthy AI systems deeply resonates with my professional passion and research background.

## Mission Alignment

My personal philosophy is to become a responsible person — for myself, my family, my community, and our society. As an ML professional, I want to take the responsibility in promoting safety and trustworthiness in the next generation of AI systems.
In the past few years, I've been dedicated to making AI systems more transparent and understandable. My efforts include but are not limited to:

- 2 peer-reviewed papers ([KDD 24'](https://arxiv.org/pdf/2406.03059), [ICDM 22'](https://arxiv.org/abs/2210.01533)) on while-box ML models
- (at Cambri) designing interpretable ML algorithms for concept validation that deliver transparent insights to clients
- (at Upright) building interpretable Bayesian models for corporate environmental impact assessment
- (at Unity) implementing SHAP-based explainability tools for production deep learning models
- actively learning about interpretability in foundation models and transformer architectures

## Technical Fit

With 9+ years of ML and software engineering experience, I bring the exact technical foundation you seek:

- **Interpretability Research**: I've published 3 papers on interpretable rule-based models and developed efficient algorithms for model exploration, achieving 1000x speedup over Google OR-tools (KDD 2024). Currently researching LLM interpretability techniques and transformer architectures.

- **ML Infrastructure & Scale**: At Unity, I deployed and maintained ML systems at scale, building privacy-constrained conversion prediction models and redesigning terabyte-scale pipelines with 25% performance improvement and $1.7M annual cost savings.

- **PyTorch & Distributed Systems**: Extensive experience across multiple projects with PyTorch, Ray, and PySpark. Built distributed training pipelines for large-scale experimentation and multi-GPU training infrastructure.

- **Research-Engineering Bridge**: Comfortable working across boundaries, from theoretical research (15+ papers at top venues like KDD, WebConf) to production systems. Built ML explainability tools using SHAP and interpretable GNN architectures for spatial analysis.

## Cultural Fit

Your values align strongly with my work approach, as evidenced by my recent "Cambri Cultural Hero" award recognizing:

- **Put mission and team first**: I believe building responsible AI requires being a responsible team member first. My collaborative spirit has consistently energized teams toward shared goals.

- **Improve constantly**: I've been the most active contributor in methodology improvements and technical enhancements across organizations, always striving for excellence in both research and engineering.

- **Take ownership and initiative**: I proactively identify problems and take full responsibility for results. From leading software architecture overhauls to building research infrastructure, I drive initiatives that matter.

- **Action today**: Having worked in fast-moving startups (my two latest positions), I thrive in high-pace environments where rapid iteration and immediate action are essential.

## Startup Experience

My recent roles at Cambri and The Upright Project have immersed me in fast-moving startup environments where I've built LaunchAI™ using fine-tuned LLMs, implemented LLM agents for automation, and developed rapid prototyping infrastructure - exactly the kind of agile, high-impact work that drives breakthrough research.

I am excited about the opportunity to contribute to Goodfire's mission of making AI interpretable and safe. Please note that I would require visa sponsorship and may qualify for the O1 visa category given my research publications and technical expertise.

Thank you for considering my application. I look forward to discussing how my interpretability research background, scalable ML engineering experience, and passion for responsible AI can contribute to Goodfire's groundbreaking work.

Sincerely,
Han Xiao
